{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import helper\n",
    "import os\n",
    "import csv\n",
    "data_dir = './data/poem.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "def load_data(path):\n",
    "    \"\"\"\n",
    "    Load Dataset from File\n",
    "    \"\"\"\n",
    "    input_file = os.path.join(path)\n",
    "    tittles = []\n",
    "    contents = []\n",
    "    with io.open(input_file, \"r\", encoding = 'utf-8') as f:\n",
    "        data = csv.reader(f)\n",
    "        for row in data:\n",
    "            tittles.append(row[0])\n",
    "            contents.append(row[1])\n",
    "\n",
    "    return tittles[1:], contents[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tittles,contents = load_data(data_dir)\n",
    "tittles = tittles[-10:]\n",
    "contents= contents[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poems = \"\"\n",
    "for poem in contents:\n",
    "    poems += poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Stats\n",
      "Roughly the number of unique words: 2321\n",
      "Number of poems: 10\n",
      "Average number of sentences in each poem: 90.0\n",
      "Number of lines: 100\n",
      "Average number of words in each line: 48.04\n",
      "\n",
      "The sentences 0 to 10:\n",
      "                        Music, when soft voices die,Vibrates in the memory;Odours, when sweet violets sicken,Live within the sense they quicken\n",
      "Rose leaves, when the rose is dead,Are heaped for the beloved's bed;And so thy thoughts, when thou art gone,Love itself shall slumber on\n",
      "                                                                     I arise from dreams of thee In the first sweet sleep of night, When the winds are breathing low, And the stars are shining bright I arise from dreams of thee, And a spirit in my feet Has led me -  who knows how? -  To thy chamber-window, sweet! The wandering airs they faint On the dark, the silent stream, -  The champak odors fall Like sweet thoughts in a dream, The nightingale's complaint, It dies upon her heart, As I must die on thine, O, beloved as thou art! O, lift me from the grass! I die, I faint, I fall! Let thy love in kisses rain On my lips and eyelids pale, My cheek is cold and white, alas! My Heart beats loud and fast Oh! press it close to thine again, Where it will break at last!                                                                     I weep for Adonais -he is dead!O, weep for Adonais! though our tearsThaw not the frost which binds so dear a head!And thou, sad Hour, selected from all yearsTo mourn our loss, rouse thy obscure compeers,And teach them thine own sorrow, say: \"With meDied Adonais; till the Future daresForget the Past, his fate and fame shall beAn echo and a light unto eternity!\"Where wert thou, mighty Mother, when he lay,When thy Son lay, pierced by the shaft which fliesIn darkness? where was lorn UraniaWhen Adonais died? With veiled eyes,Mid listening Echoes, in her ParadiseShe sate, while one, with soft enamoured breath,Rekindled all the fading melodiesWith which, like flowers that mock the corse beneath,He had adorned and hid the coming bulk of death\n",
      "O, weep for Adonais -he is dead!Wake, melancholy Mother, wake and weep!Yet wherefore? Quench within their burning bedThy fiery tears, and let thy loud heart keepLike his, a mute and uncomplaining sleep;For he is gone, where all things wise and fairDescend; -oh, dream not that the amorous DeepWill yet restore him to the vital air;Death feeds on his mute voice, and laughs at our despair\n",
      "Most musical of mourners, weep again!Lament anew, Urania! -He died,Who was the Sire of an immortal strain,Blind, old, and lonely, when his country's pride,The priest, the slave, and the liberticideTrampled and mocked with many a loathed riteOf lust and blood; he went, unterrified,Into the gulf of death; but his clear SpriteYet reigns o'er earth; the third among the sons of light\n",
      "Most musical of mourners, weep anew!Not all to that bright station dared to climb;And happier they their happiness who knew,Whose tapers yet burn through that night of timeIn which suns perished; others more sublime,Struck by the envious wrath of man or god,Have sunk, extinct in their refulgent prime;And some yet live, treading the thorny roadWhich leads, through toil and hate, to Fame's serene abode\n",
      "But now, thy youngest, dearest one, has perished - The nursling of thy widowhood, who grew,Like a pale flower by some sad maiden cherished,And fed with true-love tears, instead of dew;Most musical of mourners, weep anew!Thy extreme hope, the loveliest and the last,The bloom, whose petals nipped before they blewDied on the promise of the fruit, is waste;The broken lily lies -the storm is overpast\n",
      "To that high Capital, where kingly DeathKeeps his pale court in beauty and decay,He came; and bought, with price of purest breath,A grave among the eternal\n",
      " -Come away!Haste, while the vault of blue Italian dayIs yet his fitting charnel-roof! while stillHe lies, as if in dewy sleep he lay;Awake him not! surely he takes his fillOf deep and liquid rest, forgetful of all ill\n",
      "He will awake no more, oh, never more! - Within the twilight chamber spreads apaceThe shadow of white Death, and at the doorInvisible Corruption waits to traceHis extreme way to her dim dwelling-place;The eternal Hunger sits, but pity and aweSoothe her pale rage, nor dares she to defaceSo fair a prey, till darkness, and the lawOf change, shall o'er his sleep the mortal curtain draw\n"
     ]
    }
   ],
   "source": [
    "view_sentence_range = (0, 10)\n",
    "\n",
    "\"\"\"\n",
    "contents:list version of the poems\n",
    "poems:str version of the poems\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "print('Dataset Stats')\n",
    "print('Roughly the number of unique words: {}'.format(len({word: None for word in poems.split()})))\n",
    "\n",
    "print('Number of poems: {}'.format(len(contents)))\n",
    "sentence_count_poem = [poems.count('.') for poem in contents]\n",
    "print('Average number of sentences in each poem: {}'.format(np.average(sentence_count_poem)))\n",
    "\n",
    "sentences = [sentence for poem in contents for sentence in poem.split('.')]\n",
    "print('Number of lines: {}'.format(len(sentences)))\n",
    "word_count_sentence = [len(sentence.split()) for sentence in sentences]\n",
    "print('Average number of words in each line: {}'.format(np.average(word_count_sentence)))\n",
    "\n",
    "print()\n",
    "print('The sentences {} to {}:'.format(*view_sentence_range))\n",
    "print('\\n'.join(poems.split('.')[view_sentence_range[0]:view_sentence_range[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import problem_unittests as tests\n",
    "from collections import Counter\n",
    "\n",
    "def create_lookup_tables(text):\n",
    "    \"\"\"\n",
    "    Create lookup tables for vocabulary\n",
    "    :param text: The text of tv scripts split into words\n",
    "    :return: A tuple of dicts (vocab_to_int, int_to_vocab)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    word_counts = Counter(text)\n",
    "    sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "    int_to_vocab = {ii: word for ii, word in enumerate(sorted_vocab)}\n",
    "    vocab_to_int = {word: ii for ii, word in int_to_vocab.items()}\n",
    "\n",
    "    return vocab_to_int, int_to_vocab\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_create_lookup_tables(create_lookup_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def token_lookup():\n",
    "    \"\"\"\n",
    "    Generate a dict to turn punctuation into a token.\n",
    "    :return: Tokenize dictionary where the key is the punctuation and the value is the token\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    punk_dict = {'.':'||Period||',\n",
    "                ',':'||Comma||',\n",
    "                '\"':'||Quotation_mark||',\n",
    "                ';':'||Semicolon||',\n",
    "                '!':'||Exclamation_mark||',\n",
    "                '?':'||Question_mark||',\n",
    "                '(':'||Left_Parentheses||',\n",
    "                ')':'||Right_Parentheses||',\n",
    "                '--':'||Dash||',\n",
    "                '\\n':'||Return||'}\n",
    "    \n",
    "    return punk_dict\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_tokenize(token_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocess Training, Validation, and Testing Data\n",
    "import pickle\n",
    "def preprocess_and_save_data(text, token_lookup, create_lookup_tables):\n",
    "    \"\"\"\n",
    "    Preprocess Text Data\n",
    "    \"\"\"\n",
    "\n",
    "    # Ignore notice, since we don't use it for analysing the data\n",
    "\n",
    "    token_dict = token_lookup()\n",
    "    for key, token in token_dict.items():\n",
    "        text = text.replace(key, ' {} '.format(token))\n",
    "\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "\n",
    "    vocab_to_int, int_to_vocab = create_lookup_tables(text)\n",
    "    int_text = [vocab_to_int[word] for word in text]\n",
    "    pickle.dump((int_text, vocab_to_int, int_to_vocab, token_dict), open('preprocess.p', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocess_and_save_data(poems, token_lookup, create_lookup_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import helper\n",
    "import numpy as np\n",
    "import problem_unittests as tests\n",
    "\n",
    "int_text, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rivers/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/__main__.py:14: UserWarning: No GPU found. Please use a GPU to train your neural network.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer'\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_inputs():\n",
    "    \"\"\"\n",
    "    Create TF Placeholders for input, targets, and learning rate.\n",
    "    :return: Tuple (input, targets, learning rate)\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    tf.placeholder : placeholder(\n",
    "                        dtype\n",
    "                        shape = None,\n",
    "                        name = None)\n",
    "    \"\"\"\n",
    "    inputs = tf.placeholder(tf.int32, [None,None], name='input')\n",
    "    targets = tf.placeholder(tf.int32, [None,None], name='targets')\n",
    "    learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "    \n",
    "    return inputs, targets, learning_rate\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_inputs(get_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_init_cell(batch_size, rnn_size):\n",
    "    \"\"\"\n",
    "    Create an RNN Cell and initialize it.\n",
    "    :param batch_size: Size of batches\n",
    "    :param rnn_size: Size of RNNs\n",
    "    :return: Tuple (cell, initialize state)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    num_layers = 2\n",
    "    \n",
    "    ### Build the LSTM Cell\n",
    "    # Use a basic LSTM cell\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(rnn_size)\n",
    "    \n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([lstm] * num_layers)\n",
    "    initial_state = tf.identity(cell.zero_state(batch_size, tf.float32), name=\"initial_state\")\n",
    "   \n",
    "    return cell, initial_state\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_init_cell(get_init_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_embed(input_data, vocab_size, embed_dim):\n",
    "    \"\"\"\n",
    "    Create embedding for <input_data>.\n",
    "    :param input_data: TF placeholder for text input.\n",
    "    :param vocab_size: Number of words in vocabulary.\n",
    "    :param embed_dim: Number of embedding dimensions\n",
    "    :return: Embedded input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "\n",
    "    embedding = tf.Variable(tf.random_uniform((vocab_size, embed_dim), -1, 1))\n",
    "    embed = tf.nn.embedding_lookup(embedding, input_data)\n",
    "    return embed\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_embed(get_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def build_rnn(cell, inputs):\n",
    "    \"\"\"\n",
    "    Create a RNN using a RNN Cell\n",
    "    :param cell: RNN Cell\n",
    "    :param inputs: Input text data\n",
    "    :return: Tuple (Outputs, Final State)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "\n",
    "    outputs, final_state = tf.nn.dynamic_rnn(cell, inputs, dtype = tf.float32, initial_state = None)\n",
    "    final_state = tf.identity(final_state, name = \"final_state\")\n",
    "    return outputs, final_state\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_build_rnn(build_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def build_nn(cell, rnn_size, input_data, vocab_size, embed_dim):\n",
    "    \"\"\"\n",
    "    Build part of the neural network\n",
    "    :param cell: RNN cell\n",
    "    :param rnn_size: Size of rnns\n",
    "    :param input_data: Input data\n",
    "    :param vocab_size: Vocabulary size\n",
    "    :param embed_dim: Number of embedding dimensions\n",
    "    :return: Tuple (Logits, FinalState)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    embed = get_embed(input_data, vocab_size, embed_dim)\n",
    "    lstm_output, final_state = build_rnn(cell, embed) \n",
    "    \n",
    "    # Reshape\n",
    "    #seq_output = tf.concat(lstm_output, axis=1)\n",
    "    #x = tf.reshape(seq_output, [-1, rnn_size])\n",
    "    \n",
    "    weights = tf.truncated_normal_initializer(stddev=0.1)\n",
    "    bias = tf.zeros_initializer()\n",
    "    \n",
    "    logits = tf.contrib.layers.fully_connected(lstm_output, vocab_size, weights_initializer = weights, biases_initializer = bias, activation_fn= None)\n",
    "                       \n",
    "    return logits, final_state\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_build_nn(build_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_batches(int_text, batch_size, seq_length):\n",
    "    \"\"\"\n",
    "    Return batches of input and target\n",
    "    :param int_text: Text with the words replaced by their ids\n",
    "    :param batch_size: The size of batch\n",
    "    :param seq_length: The length of sequence\n",
    "    :return: Batches as a Numpy array\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    text_len = len(int_text)\n",
    "    total_batch = batch_size * seq_length\n",
    "    no_batches = text_len // total_batch\n",
    "    int_text = np.array(int_text[:total_batch * no_batches])\n",
    "\n",
    "    # Create offsetting targets\n",
    "\n",
    "    targets = np.zeros_like(int_text)\n",
    "    targets[:-1], targets[-1] = int_text[1:], int_text[0]\n",
    "\n",
    "    # Create output array\n",
    "\n",
    "    output = np.zeros(len(int_text) * 2)\n",
    "    output = np.resize(output,(no_batches,2,batch_size,seq_length))\n",
    "\n",
    "    # inputs\n",
    "    int_text = np.reshape(int_text,(batch_size,-1))\n",
    "\n",
    "    for bs in range(0,batch_size):\n",
    "        for nb in range(0,no_batches):\n",
    "            output[nb,0,bs] = int_text[bs,nb * seq_length : nb * seq_length + seq_length]\n",
    "\n",
    "    # targets\n",
    "    targets = np.reshape(targets,(batch_size,-1))\n",
    "\n",
    "    for bs in range(0,batch_size):\n",
    "        for nb in range(0,no_batches):\n",
    "            output[nb,1,bs] = targets[bs,nb * seq_length : nb * seq_length + seq_length]\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_batches(get_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of Epochs\n",
    "num_epochs = 1\n",
    "# Batch Size\n",
    "batch_size = 64\n",
    "# RNN Size\n",
    "rnn_size = 4\n",
    "# Embedding Dimension Size\n",
    "embed_dim = 20\n",
    "# Sequence Length\n",
    "seq_length = 8\n",
    "# Learning Rate\n",
    "learning_rate = .001\n",
    "# Show stats for every n number of batches\n",
    "show_every_n_batches = 10\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "save_dir = './save'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "from tensorflow.contrib import seq2seq\n",
    "\n",
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    vocab_size = len(int_to_vocab)\n",
    "    input_text, targets, lr = get_inputs()\n",
    "    input_data_shape = tf.shape(input_text)\n",
    "    cell, initial_state = get_init_cell(input_data_shape[0], rnn_size)\n",
    "    logits, final_state = build_nn(cell, rnn_size, input_text, vocab_size, embed_dim)\n",
    "\n",
    "    # Probabilities for generating words\n",
    "    probs = tf.nn.softmax(logits, name='probs')\n",
    "\n",
    "    # Loss function\n",
    "    cost = seq2seq.sequence_loss(\n",
    "        logits,\n",
    "        targets,\n",
    "        tf.ones([input_data_shape[0], input_data_shape[1]]))\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "    # Gradient Clipping\n",
    "    gradients = optimizer.compute_gradients(cost)\n",
    "    capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n",
    "    train_op = optimizer.apply_gradients(capped_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Batch    0/11   train_loss = 7.522\n",
      "Epoch   0 Batch   10/11   train_loss = 7.515\n",
      "Model Trained and Saved\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "batches = get_batches(int_text, batch_size, seq_length)\n",
    "\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch_i in range(num_epochs):\n",
    "        state = sess.run(initial_state, {input_text: batches[0][0]})\n",
    "\n",
    "        for batch_i, (x, y) in enumerate(batches):\n",
    "            feed = {\n",
    "                input_text: x,\n",
    "                targets: y,\n",
    "                initial_state: state,\n",
    "                lr: learning_rate}\n",
    "            train_loss, state, _ = sess.run([cost, final_state, train_op], feed)\n",
    "\n",
    "            # Show every <show_every_n_batches> batches\n",
    "            if (epoch_i * len(batches) + batch_i) % show_every_n_batches == 0:\n",
    "                print('Epoch {:>3} Batch {:>4}/{}   train_loss = {:.3f}'.format(\n",
    "                    epoch_i,\n",
    "                    batch_i,\n",
    "                    len(batches),\n",
    "                    train_loss))\n",
    "\n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, save_dir)\n",
    "    print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Save parameters for checkpoint\n",
    "helper.save_params((seq_length, save_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import helper\n",
    "import problem_unittests as tests\n",
    "\n",
    "_, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()\n",
    "seq_length, load_dir = helper.load_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_tensors(loaded_graph):\n",
    "    \"\"\"\n",
    "    Get input, initial state, final state, and probabilities tensor from <loaded_graph>\n",
    "    :param loaded_graph: TensorFlow graph loaded from file\n",
    "    :return: Tuple (InputTensor, InitialStateTensor, FinalStateTensor, ProbsTensor)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    InputTensor = loaded_graph.get_tensor_by_name('input:0')\n",
    "    InitialStateTensor = loaded_graph.get_tensor_by_name('initial_state:0')\n",
    "    FinalStateTensor = loaded_graph.get_tensor_by_name('final_state:0')\n",
    "    ProbsTensor = loaded_graph.get_tensor_by_name('probs:0')\n",
    "    \n",
    "    return InputTensor, InitialStateTensor, FinalStateTensor, ProbsTensor\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_tensors(get_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def pick_word(probabilities, int_to_vocab):\n",
    "    \"\"\"\n",
    "    Pick the next word in the generated text\n",
    "    :param probabilities: Probabilites of the next word\n",
    "    :param int_to_vocab: Dictionary of word ids as the keys and words as the values\n",
    "    :return: String of the predicted word\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    word = np.random.choice(list(int_to_vocab.values()),p=probabilities)\n",
    "    \n",
    "    return word\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_pick_word(pick_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sad Hour, selected from all mourn our loss rouse thy obscure compeers core incantation mourna mingle let happier happier thou cares massy stretch burn breakher saddened she: picturing droop watched pitched lived spreadon tender men faint among-- clips both swift lived bulk silken whose annihilation ages illumine chastisement solemn kings:look boughs wounded wont had renownrose vibrates is:what misery breathwhich no swarms ceased bethe dearwith wanderings dimmed mediterranean changed sapless in welcoming surge wither hyacinth work flocks hectic true-love seed form year bier to checks each spray true-love draw firmament build where'er man grasped guarded ploughfor west slumber fear sword thrown -it phantasies long whence shore brink peace trunkless complaint shrank full loveliest benediction bark angel lovely: sphere life's wan bedthe frost though sate wintry brainthat shattered future watch-tower depart blowher spreads visions soughther mist turn fall. stars bethe traveller rude blind driven lightleave unascended circumference: tongues shield first note crush lily sands monument immortality fairengland autumnal empty assume chariotest fire restlessly still-- icy incarnationsof comfort broken closes? reason chariotest dares world's grey well sons peace congregated findthine flight dissonant chained drearmurmur approaching hail eternity pursued spawn charnel-roof pedestal uncomplaining italian forgotten petals sounds: inmost trance defence deaf narcissus wake headof vapour unawakened again lotround aereal roadwhich refuge weak\n"
     ]
    }
   ],
   "source": [
    "gen_length = 200\n",
    "# homer_simpson, moe_szyslak, or Barney_Gumble\n",
    "prime_word = \"sad Hour, selected from all  mourn our loss rouse thy obscure compeers\"\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(load_dir + '.meta')\n",
    "    loader.restore(sess, load_dir)\n",
    "    input_text, initial_state, final_state, probs = get_tensors(loaded_graph)\n",
    "    gen_sentences = prime_word.split()\n",
    "    prev_state = sess.run(initial_state, {input_text: np.array([[1]])})\n",
    "    for n in range(gen_length):\n",
    "        # Dynamic Input\n",
    "        dyn_input = [[vocab_to_int[word] for word in gen_sentences[-seq_length:]]]\n",
    "        dyn_seq_length = len(dyn_input[0])\n",
    "\n",
    "        # Get Prediction\n",
    "        probabilities, prev_state = sess.run(\n",
    "            [probs, final_state],\n",
    "            {input_text: dyn_input, initial_state: prev_state})\n",
    "        \n",
    "        pred_word = pick_word(probabilities[dyn_seq_length-1], int_to_vocab)\n",
    "\n",
    "        gen_sentences.append(pred_word)\n",
    "    \n",
    "    # Remove tokens\n",
    "    tv_script = ' '.join(gen_sentences)\n",
    "    for key, token in token_dict.items():\n",
    "        ending = ' ' if key in ['\\n', '(', '\"'] else ''\n",
    "        tv_script = tv_script.replace(' ' + token.lower(), key)\n",
    "    tv_script = tv_script.replace('\\n ', '\\n')\n",
    "    tv_script = tv_script.replace('( ', '(')\n",
    "        \n",
    "    print(tv_script)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "   # Get Tensors from loaded model\n",
    "    input_text, initial_state, final_state, probs = get_tensors(loaded_graph)\n",
    "\n",
    "    # Sentences generation setup\n",
    "    gen_sentences = [prime_word + ':']\n",
    "    prev_state = sess.run(initial_state, {input_text: np.array([[1]])})\n",
    "\n",
    "    # Generate sentences\n",
    "    for n in range(gen_length):\n",
    "        # Dynamic Input\n",
    "        dyn_input = [[vocab_to_int[word] for word in gen_sentences[-seq_length:]]]\n",
    "        dyn_seq_length = len(dyn_input[0])\n",
    "\n",
    "        # Get Prediction\n",
    "        probabilities, prev_state = sess.run(\n",
    "            [probs, final_state],\n",
    "            {input_text: dyn_input, initial_state: prev_state})\n",
    "        \n",
    "        pred_word = pick_word(probabilities[dyn_seq_length-1], int_to_vocab)\n",
    "\n",
    "        gen_sentences.append(pred_word)\n",
    "    \n",
    "    # Remove tokens\n",
    "    tv_script = ' '.join(gen_sentences)\n",
    "    for key, token in token_dict.items():\n",
    "        ending = ' ' if key in ['\\n', '(', '\"'] else ''\n",
    "        tv_script = tv_script.replace(' ' + token.lower(), key)\n",
    "    tv_script = tv_script.replace('\\n ', '\\n')\n",
    "    tv_script = tv_script.replace('( ', '(')\n",
    "        \n",
    "    print(tv_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t =\"sad Hour, selected from all yearsTo mourn our loss, rouse thy obscure compeers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s =t.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yearsTo', 'mourn', 'our', 'loss,', 'rouse', 'thy', 'obscure', 'compeers']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[-8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
